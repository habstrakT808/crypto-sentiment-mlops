{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b96d50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Auto-Labeling with Ensemble Models\\n\",\n",
    "    \"## Phase 3: Model Development - Step 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the auto-labeling pipeline using ensemble of pre-trained models:\\n\",\n",
    "    \"- VADER Sentiment\\n\",\n",
    "    \"- TextBlob\\n\",\n",
    "    \"- FinBERT\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"project_root = Path.cwd().parent\\n\",\n",
    "    \"sys.path.insert(0, str(project_root))\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.models.labeling.auto_labeler import AutoLabeler\\n\",\n",
    "    \"from src.models.labeling.confidence_filter import ConfidenceFilter\\n\",\n",
    "    \"from src.models.labeling.label_validator import LabelValidator\\n\",\n",
    "    \"from src.data.preprocessor import TextPreprocessor\\n\",\n",
    "    \"from src.utils.config import Config\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette('husl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Imports successful!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Explore Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load data\\n\",\n",
    "    \"data_path = Config.RAW_DATA_DIR / \\\"reddit_posts_20251010_150745.csv\\\"\\n\",\n",
    "    \"df = pd.read_csv(data_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {len(df)} samples\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumns: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFirst few rows:\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Preprocess Text\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor\\n\",\n",
    "    \"preprocessor = TextPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Preprocess\\n\",\n",
    "    \"print(\\\"Preprocessing text...\\\")\\n\",\n",
    "    \"df = preprocessor.preprocess_dataframe(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✅ Preprocessing complete!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nSample preprocessed text:\\\")\\n\",\n",
    "    \"print(df['preprocessed_text'].iloc[0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Auto-Labeling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize auto-labeler\\n\",\n",
    "    \"labeler = AutoLabeler()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Label data (this will take a few minutes)\\n\",\n",
    "    \"print(\\\"Starting auto-labeling...\\\")\\n\",\n",
    "    \"df = labeler.label_dataframe(df, text_column='preprocessed_text')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n✅ Auto-labeling complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Analyze Labeling Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get statistics\\n\",\n",
    "    \"stats = labeler.get_labeling_stats(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Labeling Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"  Total samples: {stats['total_samples']}\\\")\\n\",\n",
    "    \"print(f\\\"  Average confidence: {stats['avg_confidence']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Average agreement: {stats['avg_agreement']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nLabel distribution:\\\")\\n\",\n",
    "    \"for label, count in stats['label_distribution'].items():\\n\",\n",
    "    \"    print(f\\\"  {label}: {count} ({count/stats['total_samples']*100:.1f}%)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize label distribution\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(15, 4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Label distribution\\n\",\n",
    "    \"df['auto_label'].value_counts().plot(kind='bar', ax=axes[0])\\n\",\n",
    "    \"axes[0].set_title('Label Distribution')\\n\",\n",
    "    \"axes[0].set_xlabel('Label')\\n\",\n",
    "    \"axes[0].set_ylabel('Count')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confidence distribution\\n\",\n",
    "    \"axes[1].hist(df['label_confidence'], bins=50, edgecolor='black')\\n\",\n",
    "    \"axes[1].set_title('Confidence Distribution')\\n\",\n",
    "    \"axes[1].set_xlabel('Confidence')\\n\",\n",
    "    \"axes[1].set_ylabel('Count')\\n\",\n",
    "    \"axes[1].axvline(0.6, color='r', linestyle='--', label='Threshold')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Agreement distribution\\n\",\n",
    "    \"axes[2].hist(df['label_agreement'], bins=20, edgecolor='black')\\n\",\n",
    "    \"axes[2].set_title('Agreement Distribution')\\n\",\n",
    "    \"axes[2].set_xlabel('Agreement Score')\\n\",\n",
    "    \"axes[2].set_ylabel('Count')\\n\",\n",
    "    \"axes[2].axvline(0.67, color='r', linestyle='--', label='Threshold')\\n\",\n",
    "    \"axes[2].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Validate Labels\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize validator\\n\",\n",
    "    \"validator = LabelValidator()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run validation\\n\",\n",
    "    \"validation_report = validator.comprehensive_validation(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nValidation Status: {validation_report['overall_status']}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nInter-annotator agreement: {validation_report['inter_annotator_agreement']['average_kappa']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Interpretation: {validation_report['inter_annotator_agreement']['interpretation']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Filter by Confidence\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize filter\\n\",\n",
    "    \"conf_filter = ConfidenceFilter(\\n\",\n",
    "    \"    min_confidence=0.6,\\n\",\n",
    "    \"    min_agreement=0.67,\\n\",\n",
    "    \"    use_both_criteria=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Filter data\\n\",\n",
    "    \"high_conf_df, low_conf_df = conf_filter.filter(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nHigh confidence samples: {len(high_conf_df)} ({len(high_conf_df)/len(df)*100:.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"Low confidence samples: {len(low_conf_df)} ({len(low_conf_df)/len(df)*100:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get filter stats\\n\",\n",
    "    \"filter_stats = conf_filter.get_filter_stats(high_conf_df, low_conf_df)\\n\",\n",
    "    \"print(f\\\"\\\\nHigh confidence label distribution:\\\")\\n\",\n",
    "    \"for label, count in filter_stats['high_confidence_label_dist'].items():\\n\",\n",
    "    \"    print(f\\\"  {label}: {count}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Save Labeled Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save high confidence data\\n\",\n",
    "    \"output_path = Config.PROCESSED_DATA_DIR / \\\"labeled_data.csv\\\"\\n\",\n",
    "    \"high_conf_df.to_csv(output_path, index=False)\\n\",\n",
    "    \"print(f\\\"✅ Saved {len(high_conf_df)} high confidence samples to {output_path}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save low confidence for review\\n\",\n",
    "    \"low_conf_path = Config.PROCESSED_DATA_DIR / \\\"labeled_data_low_confidence.csv\\\"\\n\",\n",
    "    \"low_conf_df.to_csv(low_conf_path, index=False)\\n\",\n",
    "    \"print(f\\\"✅ Saved {len(low_conf_df)} low confidence samples to {low_conf_path}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Sample Predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Show some examples\\n\",\n",
    "    \"print(\\\"Sample Predictions:\\\\n\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*100)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for label in ['positive', 'neutral', 'negative']:\\n\",\n",
    "    \"    print(f\\\"\\\\n{label.upper()} Examples:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\"*100)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    samples = high_conf_df[high_conf_df['auto_label'] == label].head(3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for idx, row in samples.iterrows():\\n\",\n",
    "    \"        print(f\\\"\\\\nText: {row['title'][:100]}...\\\")\\n\",\n",
    "    \"        print(f\\\"Confidence: {row['label_confidence']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"Agreement: {row['label_agreement']:.3f}\\\")\\n\",\n",
    "    \"        print(f\\\"Models: TB={row['textblob_prediction']}, VADER={row['vader_prediction']}, FinBERT={row['finbert_prediction']}\\\")\\n\",\n",
    "    \"        print(\\\"-\\\"*100)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"✅ **Auto-labeling Complete!**\\n\",\n",
    "    \"\\n\",\n",
    "    \"We have successfully:\\n\",\n",
    "    \"1. Loaded and preprocessed Reddit data\\n\",\n",
    "    \"2. Applied ensemble auto-labeling (VADER + TextBlob + FinBERT)\\n\",\n",
    "    \"3. Validated label quality\\n\",\n",
    "    \"4. Filtered high-confidence samples\\n\",\n",
    "    \"5. Saved labeled data for model training\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Next Steps:**\\n\",\n",
    "    \"- Train baseline model (Logistic Regression)\\n\",\n",
    "    \"- Train LSTM model\\n\",\n",
    "    \"- Train BERT model\\n\",\n",
    "    \"- Train FinBERT model\\n\",\n",
    "    \"- Create ensemble model\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
